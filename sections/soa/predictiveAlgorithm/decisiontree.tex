\documentclass[../../../main.tex]{subfiles}
\graphicspath{{\subfix{../../../res/}}}
\begin{document}
The Decision Tree model, in \acrshort{ml}, stand out as a fundamental and versatile algorithm. It is widely recognized for their simplicity and efficacy for classification and regression tasks alike. It is probably the most used technique in \acrshort{ml}. \cite{hofmann_rapidminer_2016}
In operations research, decision trees describe hierarchical models of decisions and their possible outcomes. In \acrshort{ml}, they refer to a predictive model.\cite{rokach_data_2015}
Decision trees have been used in a wide range of fields such the medical, game-theory, weather prediction and much more.\cite{quinlan_induction_1986}.

Their tree-like structure gave them their name to the algorithm, comprised of nodes and branches (symbolizing decisions and their possible consequences). As part of a group of analytical models aimed at making predictions, this non-parametric technique classifies a population into a branch-like segment model that constructs an inverted tree, and then this model is used to predict a target variable.\cite{song_decision_2015} This helpful visualization and interpretation makes complex decision-making processes easier and intuitive for the user. This visualization is really powerful and is an invaluable tool in various applications, ranging from data mining to advanced research in \acrfull{}{ai}.

Decision tree are used to do prediction
From the literature, decision tree seems to have a precision of around 83\% based on multiple papers (73\% \cite{viloria_integration_2019}, 87.27\% \cite{ramirez_prediction_2018}, 83\%\cite{kemper_predicting_2020} and around 90\% \cite{tenpipat_student_2020}). 
This research paper has evaluated multiple algorithm within decision tree and graphed out a \acrshort{roc} Curve for each of their algorithm. In a similar domain as this study, which is students dropout in South Korea schools and how to predict them. Their \acrshort{roc} curves showed that for a low rate of false positive, we get an outstanding true positive rate. Approximately attaining their limits around 0.2 false positive rate\cite{lee_machine_2019}. This study shows the predictive efficiency of the decision tree model. 
One downside of each study is the granularity of student prediction. They have shown which variable can be used to determine which kind of students may be at risk of dropout, but they lack a micro vision to alert staff about a specific student at risk.
\end{document}